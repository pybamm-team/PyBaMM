name: Check URLs with Lychee

on:
  push:
    branches:
      - main
      - develop
  pull_request:
  schedule:
    # Run everyday at 3 am UTC
    - cron: "0 3 * * *"


permissions: {}

jobs:
  linkChecker:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:

      # cache Lychee results to avoid hitting rate limits
      - name: Restore lychee cache
        uses: actions/cache@9255dc7a253b0ccc959486e2bca901246202afeb # v5.0.1
        with:
          path: .lycheecache
          key: cache-lychee-${{ github.sha }}
          restore-keys: cache-lychee-

      # check URLs with Lychee
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          persist-credentials: false

      # use stable version for now to avoid breaking changes
      - name: Lychee URL checker
        uses: lycheeverse/lychee-action@a8c4c7cb88f0c7386610c35eb25108e448569cb0 # v2.7.0
        with:
          # arguments with file types to check
          args: >-
            --cache
            --no-progress
            --max-cache-age 2d
            --timeout 10
            --max-retries 5
            --skip-missing
            --exclude-loopback
            --exclude https://twitter.com/pybamm_
            --exclude "https://doi\.org|www.sciencedirect\.com/*"
            --exclude https://www.rse.ox.ac.uk
            --accept 200,429
            --exclude-path ./CHANGELOG.md
            --exclude-path ./scripts/update_version.py
            --exclude-path asv.conf.json
            --exclude-path docs/conf.py
            './**/*.rst'
            './**/*.md'
            './**/*.py'
            './**/*.ipynb'
            './**/*.json'
            './**/*.toml'
          # fail the action on broken links
          fail: true
          jobSummary: true
          format: markdown
        env:
          # to be used in case rate limits are surpassed
          GITHUB_TOKEN: ${{secrets.GITHUB_TOKEN}}
