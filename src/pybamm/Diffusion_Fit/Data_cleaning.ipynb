{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main directory containing the CSV files\n",
    "main_folder = r\"C:\\UM\\Project\\PulseTest\\TVS_21700_HybridPulse_60Deg\"  # Change this to your folder path\n",
    "\n",
    "# Define the new child directory for processed data\n",
    "processed_folder = os.path.join(main_folder, \"processed_data\")\n",
    "filtered_folder = os.path.join(main_folder, \"filtered_data\")\n",
    "# Create the processed_data directory if it doesn't exist\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "# Create the filtered_data directory if it doesn't exist\n",
    "os.makedirs(filtered_folder, exist_ok=True)\n",
    "os.makedirs(trial_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: C:\\UM\\Project\\PulseTest\\TVS_21700_HybridPulse_60Deg\\processed_data\\processed_56624_TS054872.csv\n",
      "Processed and saved: C:\\UM\\Project\\PulseTest\\TVS_21700_HybridPulse_60Deg\\processed_data\\processed_56625_TS054873.csv\n",
      "Processed and saved: C:\\UM\\Project\\PulseTest\\TVS_21700_HybridPulse_60Deg\\processed_data\\processed_56626_TS054874.csv\n",
      "Processing complete. Extracted files are saved in 'processed_data' folder.\n"
     ]
    }
   ],
   "source": [
    "# Loop through all CSV files in the main folder\n",
    "for file in os.listdir(main_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(main_folder, file)\n",
    "\n",
    "        try:\n",
    "            # Open the file and detect the correct header row\n",
    "            with open(file_path, encoding=\"utf-8\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Find the header row index where \"Prog Time\" appears\n",
    "            header_row_index = None\n",
    "            for i, line in enumerate(lines):\n",
    "                if (\n",
    "                    \"Prog Time\" in line\n",
    "                    and \"Current\" in line\n",
    "                    and \"Voltage\" in line\n",
    "                    and \"AhAccu\" in line\n",
    "                ):\n",
    "                    header_row_index = i\n",
    "                    break\n",
    "\n",
    "            if header_row_index is None:\n",
    "                print(f\"Skipping {file}: No valid header found.\")\n",
    "                continue  # Skip this file\n",
    "\n",
    "            # Read the CSV file starting from the detected header row\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                encoding=\"utf-8\",\n",
    "                engine=\"python\",\n",
    "                skiprows=header_row_index,  # Skip metadata rows\n",
    "            )\n",
    "\n",
    "            # Strip spaces from column names\n",
    "            df.columns = df.columns.str.strip()\n",
    "\n",
    "            # Extract required columns if they exist\n",
    "            required_columns = [\"Prog Time\", \"Current\", \"Voltage\", \"AhAccu\"]\n",
    "            if all(col in df.columns for col in required_columns):\n",
    "                extracted_data = df[required_columns]\n",
    "\n",
    "                # Save the cleaned data in the processed folder\n",
    "                new_file_path = os.path.join(processed_folder, f\"processed_{file}\")\n",
    "                extracted_data.to_csv(new_file_path, index=False)\n",
    "                print(f\"Processed and saved: {new_file_path}\")\n",
    "            else:\n",
    "                print(f\"Skipping {file}: Required columns not found in detected data.\")\n",
    "\n",
    "        except pd.errors.ParserError as e:\n",
    "            print(f\"Skipping {file} due to parsing error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "print(\"Processing complete. Extracted files are saved in 'processed_data' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean data and remove initial charge/discharge\n",
    "def clean_and_filter_data(df):\n",
    "    # Drop the second row if it contains text (units like [A], [V])\n",
    "    if not df.iloc[1].str.isnumeric().all():\n",
    "        df = df.iloc[2:].reset_index(drop=True)  # Skip the second row\n",
    "\n",
    "    # Convert columns to numeric\n",
    "    df[\"Prog Time\"] = pd.to_numeric(df[\"Prog Time\"], errors=\"coerce\")\n",
    "    df[\"Current\"] = pd.to_numeric(df[\"Current\"], errors=\"coerce\")\n",
    "    df[\"Voltage\"] = pd.to_numeric(df[\"Voltage\"], errors=\"coerce\")\n",
    "\n",
    "    # Drop any rows with NaN values (if conversion failed)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Keep only rows where \"Prog Time\" is monotonically increasing\n",
    "    df = df[df[\"Prog Time\"].diff().fillna(0) >= 0].reset_index(drop=True)\n",
    "\n",
    "    # Remove initial long charge/discharge phase\n",
    "    threshold = 1.6  # Small threshold to detect current fluctuations\n",
    "    steady_time = 5000  # Ignore first 5000 points if current is steady\n",
    "\n",
    "    cycling_start_idx = (df[\"Current\"].diff().abs() > threshold).idxmax()\n",
    "    if cycling_start_idx > steady_time:\n",
    "        df = df.iloc[cycling_start_idx:].reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25812\\1216593723.py:8: DtypeWarning: Columns (0,1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered and saved: C:\\UM\\Project\\PulseTest\\TVS_21700_HybridPulse_60Deg\\filtered_data\\filtered_processed_56624_TS054872.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25812\\1216593723.py:8: DtypeWarning: Columns (0,1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered and saved: C:\\UM\\Project\\PulseTest\\TVS_21700_HybridPulse_60Deg\\filtered_data\\filtered_processed_56625_TS054873.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25812\\1216593723.py:8: DtypeWarning: Columns (0,1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered and saved: C:\\UM\\Project\\PulseTest\\TVS_21700_HybridPulse_60Deg\\filtered_data\\filtered_processed_56626_TS054874.csv\n",
      "Filtering complete. Cleaned files are saved in 'filtered_data' folder.\n"
     ]
    }
   ],
   "source": [
    "# Process each CSV file\n",
    "for file in os.listdir(processed_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(processed_folder, file)\n",
    "\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Clean and filter data\n",
    "            df_cleaned = clean_and_filter_data(df)\n",
    "\n",
    "            # Save the cleaned data\n",
    "            new_file_path = os.path.join(filtered_folder, f\"filtered_{file}\")\n",
    "            df_cleaned.to_csv(new_file_path, index=False)\n",
    "            print(f\"Filtered and saved: {new_file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "print(\"Filtering complete. Cleaned files are saved in 'filtered_data' folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pybamm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
